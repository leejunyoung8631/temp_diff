train_loss: 0.05739232897758484, step : 200
train_loss: 0.03126686438918114, step : 400
Epoch	1	Loss	0.0
train_loss: 0.016470320522785187, step : 600
train_loss: 0.025255080312490463, step : 800
Epoch	2	Loss	0.0
train_loss: 0.015615739859640598, step : 1000
train_loss: 0.011715196073055267, step : 1200
Epoch	3	Loss	0.0
train_loss: 0.01890278048813343, step : 1400
train_loss: 0.012291274964809418, step : 1600
Epoch	4	Loss	0.0
train_loss: 0.010599061846733093, step : 1800
train_loss: 0.01564555987715721, step : 2000
Epoch	5	Loss	0.0
train_loss: 0.013846189714968204, step : 2200
train_loss: 0.011338233947753906, step : 2400
Epoch	6	Loss	0.0
train_loss: 0.017957458272576332, step : 2600
train_loss: 0.009432917460799217, step : 2800
Epoch	7	Loss	0.0
train_loss: 0.014165437780320644, step : 3000
train_loss: 0.011987223289906979, step : 3200
Epoch	8	Loss	0.0
train_loss: 0.016858115792274475, step : 3400
train_loss: 0.009507203474640846, step : 3600
Epoch	9	Loss	0.0
train_loss: 0.012525537051260471, step : 3800
train_loss: 0.011247910559177399, step : 4000
Epoch	10	Loss	0.0
train_loss: 0.008580245077610016, step : 4200
train_loss: 0.01696343906223774, step : 4400
Epoch	11	Loss	0.0
train_loss: 0.008515425026416779, step : 4600
train_loss: 0.009713954292237759, step : 4800
train_loss: 0.010664133355021477, step : 5000
Epoch	12	Loss	0.0
train_loss: 0.017111871391534805, step : 5200
train_loss: 0.010473585687577724, step : 5400
Epoch	13	Loss	0.0
train_loss: 0.011597057804465294, step : 5600
train_loss: 0.009333855472505093, step : 5800
Epoch	14	Loss	0.0
train_loss: 0.009433891624212265, step : 6000
train_loss: 0.0087851881980896, step : 6200
Epoch	15	Loss	0.0
train_loss: 0.013522086665034294, step : 6400
train_loss: 0.0160383153706789, step : 6600
Epoch	16	Loss	0.0
train_loss: 0.01119794137775898, step : 6800
train_loss: 0.009088761173188686, step : 7000
Epoch	17	Loss	0.0
train_loss: 0.00998618733137846, step : 7200
train_loss: 0.007427715230733156, step : 7400
Epoch	18	Loss	0.0
train_loss: 0.008266279473900795, step : 7600
train_loss: 0.011326921172440052, step : 7800
Epoch	19	Loss	0.0
train_loss: 0.009951292537152767, step : 8000
train_loss: 0.008529703132808208, step : 8200
Epoch	20	Loss	0.0
train_loss: 0.01680516079068184, step : 8400
train_loss: 0.010466407053172588, step : 8600
Epoch	21	Loss	0.0
train_loss: 0.011664473451673985, step : 8800
train_loss: 0.013127981685101986, step : 9000
Epoch	22	Loss	0.0
train_loss: 0.006763048004359007, step : 9200
train_loss: 0.014471450820565224, step : 9400
Epoch	23	Loss	0.0
train_loss: 0.019043903797864914, step : 9600
train_loss: 0.008214407600462437, step : 9800
train_loss: 0.00842314027249813, step : 10000
Epoch	24	Loss	0.0
train_loss: 0.006669791880995035, step : 10200
train_loss: 0.010792410932481289, step : 10400
Epoch	25	Loss	0.0
train_loss: 0.009245958179235458, step : 10600
train_loss: 0.009769121184945107, step : 10800
Epoch	26	Loss	0.0
train_loss: 0.011500375345349312, step : 11000
train_loss: 0.0071049644611775875, step : 11200
Epoch	27	Loss	0.0
train_loss: 0.012773213908076286, step : 11400
train_loss: 0.010526257567107677, step : 11600
Epoch	28	Loss	0.0
train_loss: 0.0072753108106553555, step : 11800
train_loss: 0.008022794499993324, step : 12000
Epoch	29	Loss	0.0
train_loss: 0.00708346301689744, step : 12200
train_loss: 0.005670920480042696, step : 12400
Epoch	30	Loss	0.0
train_loss: 0.00875671673566103, step : 12600
train_loss: 0.011091470718383789, step : 12800
Epoch	31	Loss	0.0
train_loss: 0.013813077472150326, step : 13000
train_loss: 0.009926442988216877, step : 13200
Epoch	32	Loss	0.0
train_loss: 0.0070684789679944515, step : 13400
train_loss: 0.011161216534674168, step : 13600
Epoch	33	Loss	0.0
train_loss: 0.010838006623089314, step : 13800
train_loss: 0.013938916847109795, step : 14000
Epoch	34	Loss	0.0
train_loss: 0.008594539947807789, step : 14200
train_loss: 0.010215314105153084, step : 14400
Epoch	35	Loss	0.0
train_loss: 0.013225093483924866, step : 14600
train_loss: 0.009116802364587784, step : 14800
train_loss: 0.008222322911024094, step : 15000
Epoch	36	Loss	0.0
train_loss: 0.006563448812812567, step : 15200
train_loss: 0.011928888969123363, step : 15400
Epoch	37	Loss	0.0
train_loss: 0.007404324598610401, step : 15600
train_loss: 0.008926738053560257, step : 15800
Epoch	38	Loss	0.0
train_loss: 0.005806813016533852, step : 16000
train_loss: 0.008977256715297699, step : 16200
Epoch	39	Loss	0.0
train_loss: 0.012475368566811085, step : 16400
train_loss: 0.008193393237888813, step : 16600
Epoch	40	Loss	0.0
train_loss: 0.00801051314920187, step : 16800
train_loss: 0.009701868519186974, step : 17000
Epoch	41	Loss	0.0
train_loss: 0.012156303972005844, step : 17200
train_loss: 0.011681591160595417, step : 17400
Epoch	42	Loss	0.0
train_loss: 0.008601333945989609, step : 17600
train_loss: 0.008619096130132675, step : 17800
Epoch	43	Loss	0.0
train_loss: 0.011175472289323807, step : 18000
train_loss: 0.0109120924025774, step : 18200
Epoch	44	Loss	0.0
train_loss: 0.010149801149964333, step : 18400
train_loss: 0.007997792214155197, step : 18600
Epoch	45	Loss	0.0
train_loss: 0.00861189141869545, step : 18800
train_loss: 0.010197184979915619, step : 19000
Epoch	46	Loss	0.0
train_loss: 0.011380881071090698, step : 19200
train_loss: 0.009499157778918743, step : 19400
Epoch	47	Loss	0.0
train_loss: 0.007128183264285326, step : 19600
train_loss: 0.00773616461083293, step : 19800
train_loss: 0.006094330921769142, step : 20000
Epoch	48	Loss	0.0
train_loss: 0.009581530466675758, step : 20200
train_loss: 0.008742563426494598, step : 20400
Epoch	49	Loss	0.0
train_loss: 0.007600250653922558, step : 20600
train_loss: 0.007799855899065733, step : 20800
Epoch	50	Loss	0.0
train_loss: 0.006012195721268654, step : 21000
train_loss: 0.00953612755984068, step : 21200
Epoch	51	Loss	0.0
train_loss: 0.007405856624245644, step : 21400
train_loss: 0.008948457427322865, step : 21600
Epoch	52	Loss	0.0
train_loss: 0.007145726587623358, step : 21800
train_loss: 0.007400783244520426, step : 22000
Epoch	53	Loss	0.0
train_loss: 0.011529631912708282, step : 22200
train_loss: 0.01113014854490757, step : 22400
Epoch	54	Loss	0.0
train_loss: 0.00880194827914238, step : 22600
train_loss: 0.00785040482878685, step : 22800
Epoch	55	Loss	0.0
train_loss: 0.009441850706934929, step : 23000
train_loss: 0.006452112924307585, step : 23200
Epoch	56	Loss	0.0
train_loss: 0.007155750412493944, step : 23400
train_loss: 0.009069141000509262, step : 23600
Epoch	57	Loss	0.0
train_loss: 0.007504364475607872, step : 23800
train_loss: 0.007497234735637903, step : 24000
Epoch	58	Loss	0.0
train_loss: 0.004242432303726673, step : 24200
train_loss: 0.009578614495694637, step : 24400
train_loss: 0.012280631810426712, step : 24600
Epoch	59	Loss	0.0
train_loss: 0.007088829297572374, step : 24800
train_loss: 0.011632420122623444, step : 25000
Epoch	60	Loss	0.0
train_loss: 0.008016387932002544, step : 25200
train_loss: 0.007819189690053463, step : 25400
Epoch	61	Loss	0.0
train_loss: 0.011255823075771332, step : 25600
train_loss: 0.008427908644080162, step : 25800
Epoch	62	Loss	0.0
train_loss: 0.012889272533357143, step : 26000
train_loss: 0.014362041838467121, step : 26200
Epoch	63	Loss	0.0
train_loss: 0.006835338659584522, step : 26400
train_loss: 0.008373366668820381, step : 26600
Epoch	64	Loss	0.0
train_loss: 0.006797059904783964, step : 26800
train_loss: 0.009052062407135963, step : 27000
Epoch	65	Loss	0.0
train_loss: 0.006662723608314991, step : 27200
train_loss: 0.00672132195904851, step : 27400
Epoch	66	Loss	0.0
train_loss: 0.0069778733886778355, step : 27600
train_loss: 0.005753524601459503, step : 27800
Epoch	67	Loss	0.0
train_loss: 0.011100010015070438, step : 28000
train_loss: 0.008808435872197151, step : 28200
Epoch	68	Loss	0.0
train_loss: 0.009865677915513515, step : 28400
train_loss: 0.00719473185017705, step : 28600
Epoch	69	Loss	0.0
train_loss: 0.008877077139914036, step : 28800
train_loss: 0.011251655407249928, step : 29000
Epoch	70	Loss	0.0
train_loss: 0.011033674702048302, step : 29200
train_loss: 0.006954386364668608, step : 29400
train_loss: 0.005200314801186323, step : 29600
Epoch	71	Loss	0.0
train_loss: 0.008453222922980785, step : 29800
train_loss: 0.006687683053314686, step : 30000
Epoch	72	Loss	0.0
train_loss: 0.010528604499995708, step : 30200
train_loss: 0.006455530412495136, step : 30400
Epoch	73	Loss	0.0
train_loss: 0.006255489774048328, step : 30600
train_loss: 0.008658687584102154, step : 30800
Epoch	74	Loss	0.0
train_loss: 0.0089179128408432, step : 31000
train_loss: 0.00816038716584444, step : 31200
Epoch	75	Loss	0.0
train_loss: 0.006374888122081757, step : 31400
train_loss: 0.008690442889928818, step : 31600
Epoch	76	Loss	0.0
train_loss: 0.010458559729158878, step : 31800
train_loss: 0.007952209562063217, step : 32000
Epoch	77	Loss	0.0
train_loss: 0.009252486750483513, step : 32200
train_loss: 0.013615706004202366, step : 32400
Epoch	78	Loss	0.0
train_loss: 0.010498248971998692, step : 32600
train_loss: 0.00859474390745163, step : 32800
Epoch	79	Loss	0.0
train_loss: 0.007644539698958397, step : 33000
train_loss: 0.007420841138809919, step : 33200
Epoch	80	Loss	0.0
train_loss: 0.010111396200954914, step : 33400
train_loss: 0.007095090113580227, step : 33600
Epoch	81	Loss	0.0
train_loss: 0.00803194660693407, step : 33800
train_loss: 0.006108113098889589, step : 34000
Epoch	82	Loss	0.0
train_loss: 0.005127737298607826, step : 34200
train_loss: 0.006176566705107689, step : 34400
train_loss: 0.008565939031541348, step : 34600
Epoch	83	Loss	0.0
train_loss: 0.010213558562099934, step : 34800
train_loss: 0.007844535633921623, step : 35000
Epoch	84	Loss	0.0
train_loss: 0.00830414704978466, step : 35200
train_loss: 0.006585040129721165, step : 35400
Epoch	85	Loss	0.0
train_loss: 0.005921447649598122, step : 35600
train_loss: 0.00768432579934597, step : 35800
Epoch	86	Loss	0.0
train_loss: 0.006893145851790905, step : 36000
train_loss: 0.005448093172162771, step : 36200
Epoch	87	Loss	0.0
train_loss: 0.00826388318091631, step : 36400
train_loss: 0.006728110834956169, step : 36600
Epoch	88	Loss	0.0
train_loss: 0.00939926691353321, step : 36800
train_loss: 0.006621847860515118, step : 37000
Epoch	89	Loss	0.0
train_loss: 0.009787822142243385, step : 37200
train_loss: 0.0081824641674757, step : 37400
Epoch	90	Loss	0.0
train_loss: 0.007119099609553814, step : 37600
train_loss: 0.006834759842604399, step : 37800
Epoch	91	Loss	0.0
train_loss: 0.00773462513461709, step : 38000
train_loss: 0.00773218646645546, step : 38200
Epoch	92	Loss	0.0
train_loss: 0.008626826107501984, step : 38400
train_loss: 0.008723330684006214, step : 38600
Epoch	93	Loss	0.0
train_loss: 0.01104047242552042, step : 38800
train_loss: 0.008578281849622726, step : 39000
Epoch	94	Loss	0.0
train_loss: 0.005773988552391529, step : 39200
train_loss: 0.00516515364870429, step : 39400
train_loss: 0.011850262060761452, step : 39600
Epoch	95	Loss	0.0
train_loss: 0.007576236501336098, step : 39800
train_loss: 0.0051141176372766495, step : 40000
Epoch	96	Loss	0.0
train_loss: 0.013625242747366428, step : 40200
train_loss: 0.007598016876727343, step : 40400
Epoch	97	Loss	0.0
train_loss: 0.00593362795189023, step : 40600
train_loss: 0.007753423415124416, step : 40800
Epoch	98	Loss	0.0
train_loss: 0.006140868179500103, step : 41000
train_loss: 0.008659474551677704, step : 41200
Epoch	99	Loss	0.0
train_loss: 0.007700338028371334, step : 41400
train_loss: 0.005837065167725086, step : 41600
Epoch	100	Loss	0.0
train_loss: 0.007410371210426092, step : 41800
train_loss: 0.006570079363882542, step : 42000
Epoch	101	Loss	0.0
train_loss: 0.006771824322640896, step : 42200
train_loss: 0.011819812469184399, step : 42400
Epoch	102	Loss	0.0
train_loss: 0.007015177980065346, step : 42600
train_loss: 0.008516669273376465, step : 42800
Epoch	103	Loss	0.0
train_loss: 0.008796253241598606, step : 43000
train_loss: 0.006685920525342226, step : 43200
Epoch	104	Loss	0.0
train_loss: 0.005574484821408987, step : 43400
train_loss: 0.008146005682647228, step : 43600
Epoch	105	Loss	0.0
train_loss: 0.01401173323392868, step : 43800
train_loss: 0.010497570037841797, step : 44000
train_loss: 0.007591557689011097, step : 44200
Epoch	106	Loss	0.0
train_loss: 0.009472869336605072, step : 44400
train_loss: 0.011119263246655464, step : 44600
Epoch	107	Loss	0.0
train_loss: 0.005071786232292652, step : 44800
train_loss: 0.008396710269153118, step : 45000
Epoch	108	Loss	0.0
train_loss: 0.006621512118726969, step : 45200
train_loss: 0.011526801623404026, step : 45400
Epoch	109	Loss	0.0
train_loss: 0.008103393018245697, step : 45600
train_loss: 0.006623778026551008, step : 45800
Epoch	110	Loss	0.0
train_loss: 0.0089415293186903, step : 46000
train_loss: 0.005055036395788193, step : 46200
Epoch	111	Loss	0.0
train_loss: 0.00648258114233613, step : 46400
train_loss: 0.00888140220195055, step : 46600
Epoch	112	Loss	0.0
train_loss: 0.00924634374678135, step : 46800
train_loss: 0.008491788990795612, step : 47000
Epoch	113	Loss	0.0
train_loss: 0.005391949787735939, step : 47200
train_loss: 0.006685355678200722, step : 47400
Epoch	114	Loss	0.0
train_loss: 0.008159984834492207, step : 47600
train_loss: 0.008571905083954334, step : 47800
Epoch	115	Loss	0.0
train_loss: 0.006886798422783613, step : 48000
train_loss: 0.007867439649999142, step : 48200
Epoch	116	Loss	0.0
train_loss: 0.009042656980454922, step : 48400
train_loss: 0.00806553103029728, step : 48600
Epoch	117	Loss	0.0
train_loss: 0.007809705100953579, step : 48800
train_loss: 0.005352342501282692, step : 49000
train_loss: 0.009456844069063663, step : 49200
Epoch	118	Loss	0.0
train_loss: 0.00715074734762311, step : 49400
train_loss: 0.006263906601816416, step : 49600
Epoch	119	Loss	0.0
train_loss: 0.009101583622395992, step : 49800
train_loss: 0.005880242679268122, step : 50000
Epoch	120	Loss	0.0
train_loss: 0.0062997653149068356, step : 50200
train_loss: 0.008397728204727173, step : 50400
Epoch	121	Loss	0.0
train_loss: 0.009703205898404121, step : 50600
train_loss: 0.004498030990362167, step : 50800
Epoch	122	Loss	0.0
train_loss: 0.007483579218387604, step : 51000
train_loss: 0.0057188416831195354, step : 51200
Epoch	123	Loss	0.0
train_loss: 0.00502316327765584, step : 51400
train_loss: 0.007727154530584812, step : 51600
Epoch	124	Loss	0.0
train_loss: 0.006049628369510174, step : 51800
train_loss: 0.006243952549993992, step : 52000
Epoch	125	Loss	0.0
train_loss: 0.005310329142957926, step : 52200
train_loss: 0.011549761518836021, step : 52400
Epoch	126	Loss	0.0
train_loss: 0.007102478761225939, step : 52600
train_loss: 0.008428963832557201, step : 52800
Epoch	127	Loss	0.0
train_loss: 0.0057053230702877045, step : 53000
train_loss: 0.009186109527945518, step : 53200
Epoch	128	Loss	0.0
